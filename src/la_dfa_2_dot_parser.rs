// ---------------------------------------------------------
// This file was generated by parol.
// It is not intended for manual editing and changes will be
// lost after next build.
// ---------------------------------------------------------

use parol_runtime::once_cell::sync::Lazy;
#[allow(unused_imports)]
use parol_runtime::parser::{LLKParser, LookaheadDFA, ParseTreeType, ParseType, Production, Trans};
use parol_runtime::{ParolError, ParseTree};
use parol_runtime::{TokenStream, Tokenizer};
use std::cell::RefCell;
use std::path::Path;

use crate::la_dfa_2_dot_grammar::LaDfa2DotGrammar;
use crate::la_dfa_2_dot_grammar_trait::LaDfa2DotGrammarAuto;

use parol_runtime::lexer::tokenizer::{
    ERROR_TOKEN, NEW_LINE_TOKEN, UNMATCHABLE_TOKEN, WHITESPACE_TOKEN,
};

pub const TERMINALS: &[&str; 25] = &[
    /*  0 */ UNMATCHABLE_TOKEN,
    /*  1 */ UNMATCHABLE_TOKEN,
    /*  2 */ UNMATCHABLE_TOKEN,
    /*  3 */ UNMATCHABLE_TOKEN,
    /*  4 */ UNMATCHABLE_TOKEN,
    /*  5 */ r###"LookaheadDFA"###,
    /*  6 */ r###"\{"###,
    /*  7 */ r###"\}"###,
    /*  8 */ r###","###,
    /*  9 */ r###"/"###,
    /* 10 */ r###"\*"###,
    /* 11 */ r###"prod0"###,
    /* 12 */ r###":"###,
    /* 13 */ r###"transitions"###,
    /* 14 */ r###"\&"###,
    /* 15 */ r###"\["###,
    /* 16 */ r###"\]"###,
    /* 17 */ r###"Trans"###,
    /* 18 */ r###"\("###,
    /* 19 */ r###"\)"###,
    /* 20 */ r###"k"###,
    /* 21 */ r###""\w+?""###,
    /* 22 */ r###"-?\d+"###,
    /* 23 */ r###"\-"###,
    /* 24 */ ERROR_TOKEN,
];

pub const TERMINAL_NAMES: &[&str; 25] = &[
    /*  0 */ "EndOfInput",
    /*  1 */ "Newline",
    /*  2 */ "Whitespace",
    /*  3 */ "LineComment",
    /*  4 */ "BlockComment",
    /*  5 */ "LookaheadDFA",
    /*  6 */ "LBrace",
    /*  7 */ "RBrace",
    /*  8 */ "Comma",
    /*  9 */ "Slash",
    /* 10 */ "Star",
    /* 11 */ "Prod0",
    /* 12 */ "Colon",
    /* 13 */ "Transitions",
    /* 14 */ "Amp",
    /* 15 */ "LBracket",
    /* 16 */ "RBracket",
    /* 17 */ "Trans",
    /* 18 */ "LParen",
    /* 19 */ "RParen",
    /* 20 */ "K",
    /* 21 */ "NtName",
    /* 22 */ "Integer",
    /* 23 */ "Minus",
    /* 24 */ "Error",
];

/* SCANNER_0: "INITIAL" */
const SCANNER_0: (&[&str; 5], &[usize; 19]) = (
    &[
        /*  0 */ UNMATCHABLE_TOKEN,
        /*  1 */ NEW_LINE_TOKEN,
        /*  2 */ WHITESPACE_TOKEN,
        /*  3 */ r###"(//.*(\r\n|\r|\n|$))"###,
        /*  4 */ UNMATCHABLE_TOKEN,
    ],
    &[
        5,  /* LookaheadDFA */
        6,  /* LBrace */
        7,  /* RBrace */
        8,  /* Comma */
        9,  /* Slash */
        10, /* Star */
        11, /* Prod0 */
        12, /* Colon */
        13, /* Transitions */
        14, /* Amp */
        15, /* LBracket */
        16, /* RBracket */
        17, /* Trans */
        18, /* LParen */
        19, /* RParen */
        20, /* K */
        21, /* NtName */
        22, /* Integer */
        23, /* Minus */
    ],
);

const MAX_K: usize = 1;

pub const NON_TERMINALS: &[&str; 17] = &[
    /*  0 */ "CommentEnd",
    /*  1 */ "CommentStart",
    /*  2 */ "Dash",
    /*  3 */ "Integer",
    /*  4 */ "K",
    /*  5 */ "LaDfa2Dot",
    /*  6 */ "NamingComment",
    /*  7 */ "NtName",
    /*  8 */ "Parts",
    /*  9 */ "PartsOpt",
    /* 10 */ "Prod0",
    /* 11 */ "ProdNum",
    /* 12 */ "TransEntry",
    /* 13 */ "TransList",
    /* 14 */ "TransListList",
    /* 15 */ "Transitions",
    /* 16 */ "TransitionsOpt",
];

pub const LOOKAHEAD_AUTOMATA: &[LookaheadDFA; 17] = &[
    /* 0 - "CommentEnd" */
    LookaheadDFA {
        prod0: 5,
        transitions: &[],
        k: 0,
    },
    /* 1 - "CommentStart" */
    LookaheadDFA {
        prod0: 4,
        transitions: &[],
        k: 0,
    },
    /* 2 - "Dash" */
    LookaheadDFA {
        prod0: 19,
        transitions: &[],
        k: 0,
    },
    /* 3 - "Integer" */
    LookaheadDFA {
        prod0: 18,
        transitions: &[],
        k: 0,
    },
    /* 4 - "K" */
    LookaheadDFA {
        prod0: 15,
        transitions: &[],
        k: 0,
    },
    /* 5 - "LaDfa2Dot" */
    LookaheadDFA {
        prod0: 0,
        transitions: &[],
        k: 0,
    },
    /* 6 - "NamingComment" */
    LookaheadDFA {
        prod0: 6,
        transitions: &[],
        k: 0,
    },
    /* 7 - "NtName" */
    LookaheadDFA {
        prod0: 17,
        transitions: &[],
        k: 0,
    },
    /* 8 - "Parts" */
    LookaheadDFA {
        prod0: 1,
        transitions: &[],
        k: 0,
    },
    /* 9 - "PartsOpt" */
    LookaheadDFA {
        prod0: -1,
        transitions: &[Trans(0, 0, 2, 3), Trans(0, 8, 1, 2)],
        k: 1,
    },
    /* 10 - "Prod0" */
    LookaheadDFA {
        prod0: 7,
        transitions: &[],
        k: 0,
    },
    /* 11 - "ProdNum" */
    LookaheadDFA {
        prod0: 16,
        transitions: &[],
        k: 0,
    },
    /* 12 - "TransEntry" */
    LookaheadDFA {
        prod0: 14,
        transitions: &[],
        k: 0,
    },
    /* 13 - "TransList" */
    LookaheadDFA {
        prod0: 11,
        transitions: &[],
        k: 0,
    },
    /* 14 - "TransListList" */
    LookaheadDFA {
        prod0: -1,
        transitions: &[Trans(0, 16, 2, 13), Trans(0, 17, 1, 12)],
        k: 1,
    },
    /* 15 - "Transitions" */
    LookaheadDFA {
        prod0: 8,
        transitions: &[],
        k: 0,
    },
    /* 16 - "TransitionsOpt" */
    LookaheadDFA {
        prod0: -1,
        transitions: &[Trans(0, 8, 1, 9), Trans(0, 20, 2, 10)],
        k: 1,
    },
];

pub const PRODUCTIONS: &[Production; 20] = &[
    // 0 - LaDfa2Dot: NamingComment 'LookaheadDFA'^ /* Clipped */ Parts;
    Production {
        lhs: 5,
        production: &[ParseType::N(8), ParseType::T(5), ParseType::N(6)],
    },
    // 1 - Parts: '{'^ /* Clipped */ Prod0 Transitions K '}'^ /* Clipped */ PartsOpt /* Option */;
    Production {
        lhs: 8,
        production: &[
            ParseType::N(9),
            ParseType::T(7),
            ParseType::N(4),
            ParseType::N(15),
            ParseType::N(10),
            ParseType::T(6),
        ],
    },
    // 2 - PartsOpt: ','^ /* Clipped */;
    Production {
        lhs: 9,
        production: &[ParseType::T(8)],
    },
    // 3 - PartsOpt: ;
    Production {
        lhs: 9,
        production: &[],
    },
    // 4 - CommentStart: '/'^ /* Clipped */ '*'^ /* Clipped */;
    Production {
        lhs: 1,
        production: &[ParseType::T(10), ParseType::T(9)],
    },
    // 5 - CommentEnd: '*'^ /* Clipped */ '/'^ /* Clipped */;
    Production {
        lhs: 0,
        production: &[ParseType::T(9), ParseType::T(10)],
    },
    // 6 - NamingComment: CommentStart^ /* Clipped */ ProdNum Dash^ /* Clipped */ NtName CommentEnd^ /* Clipped */;
    Production {
        lhs: 6,
        production: &[
            ParseType::N(0),
            ParseType::N(7),
            ParseType::N(2),
            ParseType::N(11),
            ParseType::N(1),
        ],
    },
    // 7 - Prod0: 'prod0'^ /* Clipped */ ':'^ /* Clipped */ Integer ','^ /* Clipped */;
    Production {
        lhs: 10,
        production: &[
            ParseType::T(8),
            ParseType::N(3),
            ParseType::T(12),
            ParseType::T(11),
        ],
    },
    // 8 - Transitions: 'transitions'^ /* Clipped */ ':'^ /* Clipped */ '&'^ /* Clipped */ '['^ /* Clipped */ TransList ']'^ /* Clipped */ TransitionsOpt /* Option */;
    Production {
        lhs: 15,
        production: &[
            ParseType::N(16),
            ParseType::T(16),
            ParseType::N(13),
            ParseType::T(15),
            ParseType::T(14),
            ParseType::T(12),
            ParseType::T(13),
        ],
    },
    // 9 - TransitionsOpt: ','^ /* Clipped */;
    Production {
        lhs: 16,
        production: &[ParseType::T(8)],
    },
    // 10 - TransitionsOpt: ;
    Production {
        lhs: 16,
        production: &[],
    },
    // 11 - TransList: TransListList /* Vec */;
    Production {
        lhs: 13,
        production: &[ParseType::N(14)],
    },
    // 12 - TransListList: TransEntry TransListList;
    Production {
        lhs: 14,
        production: &[ParseType::N(14), ParseType::N(12)],
    },
    // 13 - TransListList: ;
    Production {
        lhs: 14,
        production: &[],
    },
    // 14 - TransEntry: 'Trans'^ /* Clipped */ '('^ /* Clipped */ Integer ','^ /* Clipped */ Integer ','^ /* Clipped */ Integer ','^ /* Clipped */ Integer ')'^ /* Clipped */ ','^ /* Clipped */;
    Production {
        lhs: 12,
        production: &[
            ParseType::T(8),
            ParseType::T(19),
            ParseType::N(3),
            ParseType::T(8),
            ParseType::N(3),
            ParseType::T(8),
            ParseType::N(3),
            ParseType::T(8),
            ParseType::N(3),
            ParseType::T(18),
            ParseType::T(17),
        ],
    },
    // 15 - K: 'k'^ /* Clipped */ ':'^ /* Clipped */ Integer ','^ /* Clipped */;
    Production {
        lhs: 4,
        production: &[
            ParseType::T(8),
            ParseType::N(3),
            ParseType::T(12),
            ParseType::T(20),
        ],
    },
    // 16 - ProdNum: Integer;
    Production {
        lhs: 11,
        production: &[ParseType::N(3)],
    },
    // 17 - NtName: /"\w+?"/;
    Production {
        lhs: 7,
        production: &[ParseType::T(21)],
    },
    // 18 - Integer: /-?\d+/;
    Production {
        lhs: 3,
        production: &[ParseType::T(22)],
    },
    // 19 - Dash: '-';
    Production {
        lhs: 2,
        production: &[ParseType::T(23)],
    },
];

static TOKENIZERS: Lazy<Vec<(&'static str, Tokenizer)>> = Lazy::new(|| {
    vec![(
        "INITIAL",
        Tokenizer::build(TERMINALS, SCANNER_0.0, SCANNER_0.1).unwrap(),
    )]
});

pub fn parse<'t, T>(
    input: &'t str,
    file_name: T,
    user_actions: &mut LaDfa2DotGrammar<'t>,
) -> Result<ParseTree<'t>, ParolError>
where
    T: AsRef<Path>,
{
    let mut llk_parser = LLKParser::new(
        5,
        LOOKAHEAD_AUTOMATA,
        PRODUCTIONS,
        TERMINAL_NAMES,
        NON_TERMINALS,
    );
    llk_parser.trim_parse_tree();
    let token_stream =
        RefCell::new(TokenStream::new(input, file_name, &TOKENIZERS, MAX_K).unwrap());
    // Initialize wrapper
    let mut user_actions = LaDfa2DotGrammarAuto::new(user_actions);
    llk_parser.parse(token_stream, &mut user_actions)
}
